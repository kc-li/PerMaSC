---
title: "Pre-processing"
author: "Julia Schwarz"
date: "28/10/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## Packages

```{r packages, include=FALSE}
library(lme4)
library(ggplot2)
library(lattice)
library(car)
library(lmerTest)
library(moments)
library(rcompanion)
library(MuMIn)
library(Hmisc)
library(dplyr)
library(stargazer)
```



## Data File

Raw data file with all 1-17 adults + 1-17 children, no data removed except empty responses. 4285 observations. 

```{r load data, echo=FALSE}
data<-read.csv("secondbatch.csv", header=T) 
```



## Variable Prep

```{r variables, echo=FALSE}

# Random 
data$SUBJECT <- as.factor(data$parid)
data$ITEM <- as.factor(data$number)

# Outcome Var
data$RT <- as.numeric(data$react2) #RT from the end of the sentence

# Fixed
data$GROUP <- as.factor(data$group) #adults vs children
data$AUDIO <- as.factor(data$audio) 
data$VISUAL <- as.factor(data$video)
data$PREDICT <- as.factor(data$context)
#data$TRIALORDER <- as.numeric(data$TRIALORDER)

# Other
data$ACC <- as.factor(data$accuracy) #1==correct
data$CONDITION <- as.factor(data$type)
#data$BLOCK <- as.factor(data$BLOCK)
#data$LIST <- as.factor(data$Experiment_version)

```



## Participant screening

We will exclude participants reporting low commitment to the task, any major misunderstandings of the instructions, or significant technical problems (e.g. with the experiment display), and those who do not match our recruitment criteria despite pre-screening (cf. Data collection procedures).

Excluded:

We will exclude participants with an error rate above 20% (?) (24 or more out of 120 trials). After excluding participants 4030 data points left.

Participants with error rate above 20%: NONE
Participants not meeting requirements: 
1) Dyslexia: 210725_a180, (210725_a135; not in set), (210725_c142; not in set), (210725_c97; not in set)
also c135 for now (relativey high N of error/large latencies; inspect in more detail)

```{r participants, echo=FALSE}
data <- subset(data, data$SUBJECT != '210725_a180')
data <- subset(data, data$SUBJECT != '210725_c135')
```



## Exclude training trials

8 training trials per participant excluded. Remaining data = 3785.

```{r training}
data <- subset(data, data$ITEM != '101L')
data <- subset(data, data$ITEM != '48L')
data <- subset(data, data$ITEM != '44L')
data <- subset(data, data$ITEM != '45H')
data <- subset(data, data$ITEM != '13H')
data <- subset(data, data$ITEM != '102L')
data <- subset(data, data$ITEM != '55H')
data <- subset(data, data$ITEM != '52H')
```



## Exclude incorrect trials

Incorrect and problematic trials were removed (N=164, 4.3%). Remaining data = 3621.

```{r incorrect}
data <- subset(data, data$ACC != 0)
3785-3621
164/3785
```



## Items and trials (exclude items w high error rate)

Target words with an error rate of 40% or higher (cf. Crepaldi et al. 2016) will be removed from the analysis. 

Items w 40% error rate or higher: NONE (?)

[[In addition, we might remove all trials where the target was ambiguous (charity meal, knob, a net); for now, none removed]].

```{r items, echo=FALSE}
itemnumbers <- groupwiseMean(RT ~ ITEM,
                           data   = data,
                           conf   = 0.95,
                           digits = 3)
#data <- subset(data, data$ITEM !='...') 
```



## Inspect data and remove unnatural responses

Unnatural reaction times below 0ms and above 3000ms were removed since they indicate insufficient attention (N=22; Fairs & Strijkers allow 2000ms for picture naming; Vogt, Hauber, Kuhlen & Rahman allowed 3000ms for picture naming from onset; Kessler, Treiman & Mullennix allowed 2000ms for word reading). 

After this cleaning process, reaction times will be inspected with histograms, with boxplots, and by Participant with qqplot. 
Data remaining: 3606.

```{r outliers, echo=FALSE}
data <- subset(data, data$RT > 0) #1 trial removed
data <- subset(data, data$RT < 3000) #15 trials removed
3621-3606

hist(data$RT, breaks = 30)
boxplot(data$RT)
skewness(data$RT, na.rm = TRUE) # 0.8570 slightly positively skewed

qqmath(~RT|SUBJECT, data=data, main="Responses by Subject")

```



## Transform reaction times and remove outliers

The data were found to be positively skewed. Therefore we tested common transformations (actually only tested log so far) and chose the one with the best fit/but found no satisfactory improvement. Outliers three standard deviations from the mean per participant were removed.

Data remaining: 3560.

```{r transformation, echo=FALSE}

data$LogRT <- log(data$RT)
data$LogRT <- as.numeric(data$LogRT)
hist(data$LogRT)
boxplot(data$LogRT)
skewness(data$LogRT, na.rm = TRUE) #-0.96 = worse fit

outliers <- data %>% group_by(SUBJECT) %>% filter(!(abs(RT - mean(RT)) < 3*sd(RT))) #46 obs.
data <- data %>% group_by(SUBJECT) %>% filter(!(abs(RT - mean(RT)) > 3*sd(RT)))

skewness(data$RT, na.rm = TRUE) #0.83
hist(data$RT, breaks = 30)
qqmath(~RT|SUBJECT, data=data, main="Responses by Subject")

```



## Save cleaned data sheet

```{r save}
write.table(data, "211029_subset_data_cleaned.txt", sep="\t", row.names=FALSE)
```



