---
title: "gorillatime"
author: "Katrina Li"
date: "03/03/2022"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(patchwork)
```

```{r read data}
adultgorilla <- read.csv("questionnaire/adult_gorillatime.csv")
childgorilla <- read.csv("questionnaire/child_gorillatime.csv")
gorilla <- rbind(adultgorilla, childgorilla)
gorilla$file <- basename(gorilla$filename)
gorilla$path <- dirname(gorilla$filename)
gorilla$path <- str_extract(gorilla$path, "\\w+\\s*randomizer$")
#gorilla$Response <- as.factor(gorilla$Response)
#levels(gorilla$Response)
```

```{r identify error messages tokens}
# 1. No source for the media file 8H_aM_vM.mp4 could be found! Most likely this is because the file has not been uploaded to your stimuli list or its name has been typed incorrectly in the spreadsheet	
nosource <- gorilla %>%
  filter(grepl('No source',Response)) 

nosource%>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

# 2. ID MISMATCH! Result ID: 1629231782397 does not match Recording ID of 0
idmismatch <- gorilla %>%
  filter(grepl('ID MISMATCH',Response)) 

idmismatch%>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

# 3. loading delay - not about specific tokens
delay <- gorilla %>%
  filter(grepl('delay',Response))

delay.table <- delay %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())
write.table(delay.table,"interspeech/delay.txt",sep = "\t", row.names = FALSE)

# 4. media err decode - c 15 rows
#MEDIA_ERR_DECODE: An error of some description occured while decoding the media resource, after the resource was established to be usable	
media.err.decode <- gorilla %>%
  filter(grepl('MEDIA_ERR_DECODE',Response))

# 5. media ERR_SRC_NOT_SUPPORTED a151 2 rows
#MEDIA_ERR_SRC_NOT_SUPPORTED: The media resource indicated by the src attribute was either missing or not supported by the browser	
media.err.src <- gorilla %>%
  filter(grepl('MEDIA_ERR_SRC',Response))

# 6. Unexpectedly long close out at end of task! - not about specific tokens
unexpected <- gorilla %>%
  filter(grepl('Unexpectedly',Response))

unexpected.table <- unexpected %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())
write.table(unexpected.table,"interspeech/unexpected.txt",sep = "\t", row.names = FALSE)

# 7. "RECORDING ERROR" #only c35
recordingerror <- gorilla %>%
  filter(grepl('RECORDING ERROR',Response))

recordingerror %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())
```

```{r exclude error message tokens}
excludeset <- rbind(nosource,idmismatch,media.err.decode,media.err.src,recordingerror)
gorilla.clean <- gorilla %>% 
  anti_join(excludeset, by = c("Participant.Public.ID","videoname")) %>%
  #filter(!grepl('No source',Response)) %>%
  #filter(!grepl('ID MISMATCH',Response)) %>%
  filter(!grepl('delay',Response)) %>%
  #filter(!grepl('MEDIA_ERR_DECODE',Response)) %>%
  #filter(!grepl('MEDIA_ERR_SRC',Response)) %>%
  filter(!grepl('Unexpectedly',Response)) %>%
  #filter(!grepl('RECORDING ERROR',Response)) %>%
  filter(Response != "") %>%
  mutate(Response = as.factor(Response))
levels(gorilla.clean$Response) 

gorilla.clean <- gorilla.clean %>%
  mutate(
    Responsetype = case_when(
      Response == "STARTED RECORDING" ~1,
      Response == "VIDEO STARTED"  ~2,
      Response == "VIDEO PLAYING EVENT FIRED"   ~3,
      Response == "VIDEO TIMEUPDATE EVENT FIRED"  ~4,
      Response == "ADJUSTED START TIME based on TIMEUPDATE EVENT"  ~5,
      Response == "VIDEO ENDED EVENT FIRED"  ~6,
      Response == "Next"  ~7,
      Response == "STOPPED RECORDING"  ~8,
    )
  )
```

```{r identify repetiting okens}
# How many tokens will result in non-unique combination
gorilla.wide <- gorilla.clean %>%
  pivot_wider(
    id_cols = c("Participant.Public.ID","Task.Version","Spreadsheet","videoname","display","path","file"), 
    names_from = "Responsetype",
    names_prefix = "T",
    values_from = "Reaction.Time",
        values_fn = length)

T1.rep.token <- gorilla.wide %>%
  filter(T1 > 1) 
T1.rep <- gorilla.wide %>%
  filter(T1 > 1) %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

T2.rep.token <- gorilla.wide %>%
  filter(T2 > 1) 
T2.rep <- gorilla.wide %>%
  filter(T2 > 1) %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

T3.rep.token <- gorilla.wide %>%
  filter(T3 > 1)
T3.rep <- gorilla.wide %>%
  filter(T3 > 1) %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

T4.rep.token <- gorilla.wide %>%
  filter(T4 > 1)
T4.rep <- gorilla.wide %>%
  filter(T4 > 1) %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

T5.rep.token <- gorilla.wide %>%
  filter(T5 > 1)
T5.rep <- gorilla.wide %>%
  filter(T5 > 1) %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

T6.rep.token <- gorilla.wide %>%
  filter(T6 > 1)
T6.rep <- gorilla.wide %>%
  filter(T6 > 1) %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

T7.rep.token <- gorilla.wide %>%
  filter(T7 > 1)
T7.rep <- gorilla.wide %>%
  filter(T7 > 1) %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

T8.rep.token <- gorilla.wide %>%
  filter(T8 > 1)
T8.rep <- gorilla.wide %>%
  filter(T8 > 1) %>%
  group_by(Participant.Public.ID) %>%
  summarise(n = n())

write.table(T1.rep,"interspeech/20220308T1rep.txt",sep = "\t", row.names = FALSE)
write.table(T2.rep,"interspeech/20220308T2rep.txt",sep = "\t", row.names = FALSE)
write.table(T3.rep,"interspeech/20220308T3rep.txt",sep = "\t", row.names = FALSE)
write.table(T4.rep,"interspeech/20220308T4rep.txt",sep = "\t", row.names = FALSE)
write.table(T5.rep,"interspeech/20220308T5rep.txt",sep = "\t", row.names = FALSE)
write.table(T6.rep,"interspeech/20220308T6rep.txt",sep = "\t", row.names = FALSE)
write.table(T7.rep,"interspeech/20220308T7rep.txt",sep = "\t", row.names = FALSE)
write.table(T8.rep,"interspeech/20220308T8rep.txt",sep = "\t", row.names = FALSE)

```



```{r excluding rows with multiple video plays}
# How many tokens will result in non-unique combination
# gorilla.norep <- gorilla.clean %>%
#   anti_join(T1.rep.token, by = c("Participant.Public.ID","videoname")) %>%
#   anti_join(T2.rep.token, by = c("Participant.Public.ID","videoname")) %>%
#   anti_join(T3.rep.token, by = c("Participant.Public.ID","videoname")) %>%
#   anti_join(T4.rep.token, by = c("Participant.Public.ID","videoname")) %>%
#   anti_join(T5.rep.token, by = c("Participant.Public.ID","videoname")) %>%
#   anti_join(T6.rep.token, by = c("Participant.Public.ID","videoname")) %>%
#   anti_join(T7.rep.token, by = c("Participant.Public.ID","videoname")) %>%
#   anti_join(T8.rep.token, by = c("Participant.Public.ID","videoname"))
# 
# gorilla.norep.wide <- gorilla.norep %>%
#   pivot_wider(
#     id_cols = c("Participant.Public.ID","Task.Version","Spreadsheet","videoname","display","path","file"),
#     names_from = "Responsetype",
#     names_prefix = "T",
#     values_from = "Reaction.Time") %>%
#     mutate(
#     parid = Participant.Public.ID,
#     T1 = as.numeric(T1),
#     T1 = replace_na(T1,0),
#     T2 = as.numeric(T2),
#     T3 = as.numeric(T3),
#     T4 = as.numeric(T4),
#     T5 = as.numeric(T5),
#     T6 = as.numeric(T6),
#     T7 = as.numeric(T7),
#     T8 = as.numeric(T8),
#   )
```

```{r excluding rows with multiple video plays}
# How many tokens will result in non-unique combination
gorilla.norep <- gorilla.clean %>%
  anti_join(T1.rep.token, by = c("Participant.Public.ID","videoname")) %>%
  anti_join(T2.rep.token, by = c("Participant.Public.ID","videoname")) %>%
  anti_join(T3.rep.token, by = c("Participant.Public.ID","videoname")) %>%
  anti_join(T4.rep.token, by = c("Participant.Public.ID","videoname")) %>%
  #anti_join(T5.rep.token, by = c("Participant.Public.ID","videoname")) %>%
  anti_join(T6.rep.token, by = c("Participant.Public.ID","videoname")) %>%
  anti_join(T7.rep.token, by = c("Participant.Public.ID","videoname")) %>%
  anti_join(T8.rep.token, by = c("Participant.Public.ID","videoname"))

gorilla.norep.wide <- gorilla.norep %>%
  pivot_wider(
    id_cols = c("Participant.Public.ID","Task.Version","Spreadsheet","videoname","display","path","file"), 
    names_from = "Responsetype",
    names_prefix = "T",
    values_from = "Reaction.Time",
    values_fn = last) %>%
    mutate(
    parid = Participant.Public.ID,
    T1 = as.numeric(T1),
    T1 = replace_na(T1,0),
    T2 = as.numeric(T2),
    T3 = as.numeric(T3),
    T4 = as.numeric(T4),
    T5 = as.numeric(T5),
    T6 = as.numeric(T6),
    T7 = as.numeric(T7),
    T8 = as.numeric(T8),
  )
```

```{r merge with RT assist_final data}
#Let's only focus on when the relevant participants
data<-read.delim("interspeech/220322RTassist_final.txt", sep="\t", header=T) 

data.join <- data %>%
  inner_join(gorilla.norep.wide, by = c("parid","videoname"))

#786 rows not matched - those with double playing (error messages recordings will not be included anyway)
data %>%
  anti_join(gorilla.norep.wide, by = c("parid","videoname"))
```
```{r read the start of the measurefiles & stimuli files}
# Read into measure file start and merge
startpath <- "interspeech/soundstart_measure"
start <- list.files(startpath,pattern = "start.txt",full.names = T)
startfiles <-tibble(File = start) %>%
  extract(File, "parid","([0-9]{6}_[ac][0-9]*measure_start)",remove = FALSE) %>%
  mutate(Data = lapply(File, read.delim, sep = "\t")) %>%
  unnest(Data)%>%
  select(-File)%>%
  mutate(label = str_replace_all(label,"\\.","")) %>% # Replace extra '.' symbol at the end
  mutate(label = str_replace_all(label,"\\_$","")) %>%# Replace extra '_' symbol at the end
  mutate(label = str_replace_all(label,",$","")) %>%
  mutate(parid = substr(parid, 1, nchar(parid)-13)) %>%
  rename(start_time_measure = start_time)

##merge 
data.join.start.m <- data.join %>%
  inner_join(startfiles, by = c("parid" = "parid","original_label"="label"))

#### a120 137L lost data point because 
data.join %>%
  anti_join(startfiles, by = c("parid" = "parid","original_label"="label"))

  
# Read the start of stimuli files and merge with stimulim to derive X3
stimuli.start1 <- read.delim("interspeech/soundstart_stimuli/aM_annotation2_start.txt",sep = "\t")
stimuli.start2 <- read.delim("interspeech/soundstart_stimuli/aNM_annotation2_start.txt",sep = "\t")
stimuli.start <- rbind(stimuli.start1, stimuli.start2)
stimuli.start <- stimuli.start %>%
  rename(start_time_stimuli = start_time)

stimulim <- read.csv("datafile_first_batch/stimulim.csv",header = T)
stimulim.length <- stimulim %>%
  select(sentence_label,time_p2) %>%
  inner_join(stimuli.start, by = c("sentence_label" = "label")) %>%
  mutate(X3 = (time_p2 - start_time_stimuli)*1000)

```

```{r }
data.final <- data.join.start.m %>%
  mutate(sentence_label = paste0(number, "_",audio)) %>%
  left_join(stimulim.length, by = c("sentence_label")) %>%
  mutate(
    duration2 = beep_response - (rstart-b),
    X1 = (rstart + duration2 - start_time_measure)*1000,
    X2 = T5-T1,
    RT.alter = X1-X2-X3,
    diff.alter = RT.alter - RT)

data.final %>%
  ggplot(aes(x=diff.alter)) +
  geom_histogram(binwidth = 10)
# mosty very small, but seems to have peculiar values
```

```{r write data}
write.table(data.final,"interspeech/220322datafinal.txt", sep= "\t", row.names = FALSE)
```




