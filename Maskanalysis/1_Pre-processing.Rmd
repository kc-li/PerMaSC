---
title: "Pre-processing"
author: "Julia Schwarz"
date: "28/10/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages

```{r packages, include=FALSE}
library(lme4)
library(ggplot2)
library(lattice)
library(car)
library(lmerTest)
library(moments)
library(rcompanion)
library(MuMIn)
library(Hmisc)
library(dplyr)
library(stargazer)
```

## Updates compared to the previous version (to be discussed):
- c135 is re-introuded and re-evaluated, as there are worse dataset than that.
- New variables introduced: age, sex, trial, block
- Reaction time lower than 0 ms is not excluded, since this time we have much more data below 0ms. However, for log transformation, adding a small value to it and make all data positive might give better distribution.
- We also inspect annotation notes.
- Transfomation not decided yet.

## Data File

Raw data file with all 33 adults + 31 children, no data removed except empty responses. **7853** observations. 

From first batch of files: 17 adults and 17 children.

From second batch of files: 16 adults and 14 children.

```{r load data, echo=FALSE}
data<-read.csv("fulldata.csv", header=T) 
print(paste("Total data: ", nrow(data)))

data[!duplicated(data$parid),] %>%
  group_by(group) %>%
  summarise(n = n())
```

## Variable Prep
New variables here: *TRIAL*, *BLOCK*, *AGE*, *SEX*

```{r variables, echo=FALSE}

# Random 
data$SUBJECT <- as.factor(data$parid)
data$ITEM <- as.factor(data$number)

# Outcome Var
data$RT <- as.numeric(data$react2) #RT from the end of the sentence

# Fixed
data$GROUP <- as.factor(data$group) #adults vs children
data$AUDIO <- as.factor(data$audio) 
data$VIDEO <- as.factor(data$video)
data$PREDICT <- as.factor(data$context)
#data$TRIALORDER <- as.numeric(data$TRIALORDER)

# For figures and models
data$GROUP <- factor(data$GROUP, levels = c("a","c"), labels = c("Adults", "Children"))
data$ACOUSTIC <- factor(data$AUDIO, levels = c("aNM","aM"), labels = c("No Acoustic Mask", "Acoustic Mask")) 
data$VISUAL <- factor(data$VIDEO, levels = c("vNM","vM"), labels = c("No Visual Mask", "Visual Mask"))
data$PREDICTABILITY <- factor(data$PREDICT, levels = c("H","L"), labels = c("High Predictability", "Low Predictability"))

# Other
data$ACC <- as.factor(data$accuracy) #1==correct
data$CONDITION <- as.factor(data$type)
data$TRIAL <- as.numeric(data$row_number) 
data$BLOCK <- as.numeric(data$block)

# Only 2 people's age information is not finished yet!
data$AGE <- as.numeric(data$date.of.birth_year + data$date.of.birth_month/12)
data$SEX <- as.factor(data$sex)

#data$LIST <- as.factor(data$Experiment_version)
```

## Exclude training trials

8 training trials per participant excluded. Remaining data = **7378**.

```{r training}
data <- data %>%
  filter(display != "Practice") # the same as below
data <- subset(data, data$ITEM != '101L')
data <- subset(data, data$ITEM != '48L')
data <- subset(data, data$ITEM != '44L')
data <- subset(data, data$ITEM != '45H')
data <- subset(data, data$ITEM != '13H')
data <- subset(data, data$ITEM != '102L')
data <- subset(data, data$ITEM != '55H')
data <- subset(data, data$ITEM != '52H')
print(paste("Remaining data: ", nrow(data)))
```

## Participant screening
Based on the examination of recordings, we excluded participants reporting low commitment to the task (irrelevant speaking, background noise), any major misunderstandings of the instructions, or significant technical problems (e.g. with the experiment display). Relative information are noted down in the Google sheet 'Missing Trials or Answers'.

Besieds, based on the post-experiment questionnaire, we excluded participants who do not match our recruitment criterial despite pre-screening (e.g. dyslexia, cf. Data collection procedures). 

**Exclude a180 - dyalexia; 210725_a113 - effot doubtful; 210719_a59 - poor recording quality.**

Remaining data: **7018**

```{r participants, echo=FALSE}
data <- subset(data, data$SUBJECT != '210725_a180')
data <- subset(data, data$SUBJECT != '210725_a113')
data <- subset(data, data$SUBJECT != '210719_a59')
print(paste("Remaining data: ", nrow(data)))
```

The rest filtering are based on data patterns.

### Based on the total number of trials
There are four children whose usable datapoints are less than 100, indicating the technical problems might be severe. We need to check these individual data to see distributions.
210719_c43:79
210719_c45:82
210725_c96:75
210725_c98:72

**c43, c45, c96, c98 not enough data.**

**Exclude c96: Age 13 (72 reponses)**
**Or should we exclude c98 which has 57 responses?**

Remaining data: **6961**

Now we have 30 adults and 30 children.
```{r}
data %>%
  group_by(GROUP, parid) %>%
  summarise(count = n()) %>%
  filter(count<100)

data <- subset(data, data$SUBJECT != '210725_c98')

print(paste("Remaining data: ", nrow(data)))
```
```{r}
# Check if adult & children match
data[!duplicated(data$parid),] %>%
  group_by(GROUP) %>%
  summarise(n = n())
# Check if sex match
data[!duplicated(data$parid),] %>%
  group_by(GROUP,SEX) %>%
  summarise(n = n())
```


### Based on accuracy
We will exclude participants with an error rate above 20% . 

Participants with error rate above 20%: NONE
Participants with error rate above 10%: c29, c135

**c29 and c135 needs inspection.**

**No exclusion**


```{r}
data %>%
  group_by(parid) %>%
  summarise(errorrate = (1-sum(accuracy)/n())*100) %>%
  filter(errorrate > 10)
```

## Items and trials (exclude items w high error rate)

Target words with an error rate of 40% or higher (cf. Crepaldi et al. 2016) will be removed from the analysis. 

Items w 40% error rate or higher: NONE
Items w higher than 20% error rate: 
64L: 21.4%
21L: 20.6%

**No targets removed based on error rate. **

**We excluded three ambiguous target words: knob, meal, net.**

Remaining trials: **6787**
```{r}
data %>%
  group_by(ITEM) %>%
  summarise(errorrate = 100*(1-sum(accuracy)/n())) %>%
  filter(errorrate > 20)
data <- subset(data, data$correctans != 'knob')
data <- subset(data, data$correctans != 'meal')
data <- subset(data, data$correctans != 'net')

print(paste("Remaining trials: ", nrow(data)))
```


### Exclude trials with notes of 'discard'
In the correct responses (ACC ==1), we delete the ones with 'discard' marking (7 removed), because it's not possible to mark the speech onset accurately, but we keep the ones with 'unsure' marking (including participants sounding unsure; and coder unsure because of overlapping sound.)

Remaining data = **6779**.

```{r inspect data, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#7 noted as 'discard' in ACC==1 -> accurate
## Take out
data %>%
  filter(ACC ==1) %>%
  filter(grepl('discard',note))

# Noted with unsure: Keep them all
data %>%
  filter(ACC ==1) %>%
  filter(grepl('unsure',note))
```

```{r}
# The negation of (data$ACC = 1 & grepl('discard',note))
data <- subset(data, data$ACC !=1 | !grepl('discard',note))
print(paste("Remaining trials: ", nrow(data)))
# store the number at the current stage
x = nrow(data)
```



### Exclude incorrect trials
Incorrect and problematic trials were removed (N=272, 4.01%). 
We will analyse wrong trials separately.

Remaining trials: **6507**

```{r export error data}
error <- subset(data, data$ACC!=1)
write.csv(error,"220112_unfiltered_error.csv")
```

```{r exclude error data}
data <- subset(data, data$ACC != 0)
print(paste("Wrong trials: ", x-nrow(data), "(error rate: ", 100*(x-nrow(data))/x, ")"))
print(paste("Remaining trials: ", nrow(data)))
```


```{r items, echo=FALSE}
# We checked for each item, we have enough data (18-38)
itemnumbers <- groupwiseMean(RT ~ ITEM,
                           data   = data,
                           conf   = 0.95,
                           digits = 3)
#data <- subset(data, data$ITEM !='...') 
```



## Inspect data and remove unnatural responses
```{r}
range(data$RT)
data$RTcut = cut(data$RT,breaks = c(-500,-50,0,1000,3000,20000))
table(data$RTcut)
```

Unnatural reaction times below 0ms and above 3000ms were removed since they indicate insufficient attention (N=22; Fairs & Strijkers allow 2000ms for picture naming; Vogt, Hauber, Kuhlen & Rahman allowed 3000ms for picture naming from onset; Kessler, Treiman & Mullennix allowed 2000ms for word reading). 

After this cleaning process, reaction times will be inspected with histograms, with boxplots, and by Participant with qqplot. 
Data remaining: **6477**.

```{r outliers, echo=FALSE}
data <- subset(data, data$RT < 3000) #29 trials removed
print(paste("Remaining trials: ", nrow(data)))

hist(data$RT, breaks = 30)
boxplot(data$RT)
skewness(data$RT, na.rm = TRUE) # 0.8570 slightly positively skewed

qqmath(~RT|SUBJECT, data=data, main="Responses by Subject")

```

### Distraction and Difficulty (commitment to the experiment)
Difficulty.y >3: **210723_a78** (Difficulty 5, Distraction 3)

Distraction >3: **210725_c133** (Difficulty 2, Disctraction 4)

**Nothing excluded**

```{r filtering, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
data[!duplicated(data$parid),] %>%
  filter(Difficulty.y > 3)

data[!duplicated(data$parid),] %>%
  filter(Distraction > 3)
```


```{r}
# remove duplicated, only consider one line per participant
# CI interval
diffi_distr <- data[!duplicated(data$parid),] %>%
  summarise(difficulty.mean = mean(Difficulty.y), 
            difficulty.sd = sd(Difficulty.y),
            n = n(),
            diffculty.min = min(Difficulty.y), 
            diffculty.max = max(Difficulty.y), 
            distraction.mean = mean(Distraction),
            distraction.sd = sd(Distraction),
            distraction.min = min(Distraction), 
            distraction.max = max(Distraction),
            )%>%
  mutate(difficulty.se = difficulty.sd/sqrt(n),
         distraction.se = distraction.sd/sqrt(n),
         difficulty.lower.ci = difficulty.mean - qt(1-(0.05/2), n -1) * difficulty.se,
         difficulty.upper.ci = difficulty.mean + qt(1-(0.05/2), n -1) * difficulty.se,
         distraction.lower.ci = distraction.mean - qt(1-(0.05/2), n -1) * distraction.se,
         distraction.upper.ci = distraction.mean + qt(1-(0.05/2), n -1) * distraction.se
  ) %>%
  select(difficulty.mean, difficulty.sd, difficulty.lower.ci, difficulty.upper.ci, distraction.mean, distraction.sd, distraction.lower.ci, distraction.upper.ci)
diffi_distr
# difficultymean <- groupwiseMean(Difficulty.y,
#                            data   = Qpart,
#                            conf   = 0.95,
#                            digits = 3)

```


## Transform reaction times and remove outliers

The data were found to be positively skewed. Therefore we tested common transformations (actually only tested log so far) and chose the one with the best fit/but found no satisfactory improvement. Outliers three standard deviations from the mean per participant were removed.

Data remaining: 6387.

```{r transformation, echo=FALSE}
skewness(data$RT, na.rm = TRUE)
hist(data$RT, breaks = 30)
data$LogRT <- log(data$RT)
data$LogRT <- as.numeric(data$LogRT)
data$RT500 <- data$RT + 500
data$logRT500 <- log(data$RT500)
data$logRT500 <- as.numeric(data$logRT500)
hist(data$LogRT,breaks = 30)
hist(data$logRT500,breaks = 30)
boxplot(data$LogRT)
skewness(data$LogRT, na.rm = TRUE) #-0.96 = worse fit
skewness(data$logRT500, na.rm = TRUE) #-0.96 = worse fit

outliers <- data %>% group_by(SUBJECT) %>% filter(!(abs(RT - mean(RT)) < 3*sd(RT))) #92 obs.
data <- data %>% group_by(SUBJECT) %>% filter(!(abs(RT - mean(RT)) > 3*sd(RT)))

skewness(data$RT, na.rm = TRUE) #1.4275
hist(data$RT, breaks = 30)
qqmath(~RT|SUBJECT, data=data, main="Responses by Subject")

```



## Save cleaned data sheet

```{r save}
write.table(data, "220112_full_data_cleaned.txt", sep="\t", row.names=FALSE)
```


